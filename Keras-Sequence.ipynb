{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a model on a large dataset that does not fit into memory, you can write a custom generator that can pass the data to the model in batches. Once you have the generator, fitting the model is as simple as calling ```fit_generator()``` instead of ```fit()``` on the Keras model. You can include data preprocessing or data augmentation in the generator.\n",
    "\n",
    "As of Keras 2.0.6, a [Sequence](https://keras.io/utils/#sequence) object is available that allows for safe multiprocessing:\n",
    "\n",
    "> Sequence are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators.\n",
    "\n",
    "Allowing for multiprocessing can lead to large speedups in training and can help to avoid bottlenecking a GPU. This notebook contains an minnimal working example on how to use a ```Sequence``` object to fit a Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import Sequence\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to classify whether an MNIST image contains a 0 or an 8. The raw images should sit in the folder ```./im```. You can download the images and labels from http://yann.lecun.com/exdb/mnist/. I converted the labels into .csv files which you can find in this repository. These files provide a mapping from image names to labels (a 0 is labelled as 0, an 8 as 1 in the dataframes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_9847.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_33541.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_20295.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_35648.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_24267.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_name  label\n",
       "0   img_9847.jpg      1\n",
       "1  img_33541.jpg      1\n",
       "2  img_20295.jpg      1\n",
       "3  img_35648.jpg      0\n",
       "4  img_24267.jpg      0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./TRAIN.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example code from the Keras docs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class CIFAR10Sequence(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (200, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this code, I will add the following methods:\n",
    "    * `on_epoch_end` to shuffle the indices after each epoch when in training mode\n",
    "    * `get_batch_labels` and `get_batch_features` will implement the necessary logic which is different for the labels (which are held in memory) and the images (which are read from disk). Both of these methods behave differently for the last batch. This is to make sure that no data is skipped, even if the final batch is smaller than the batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from math import ceil\n",
    "import random\n",
    "\n",
    "datapath = './im/'\n",
    "\n",
    "class DataSequence(Sequence):\n",
    "    \"\"\"\n",
    "    Keras Sequence object to train a model on larger-than-memory data.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, data_path, batch_size, mode='train'):\n",
    "        self.df = df\n",
    "        self.dp = data_path # path tothe raw images\n",
    "        self.bsz = batch_size\n",
    "        self.mode = mode\n",
    "\n",
    "        # Take labels and a list of image locations in memory\n",
    "        self.labels = self.df['label'].values\n",
    "        self.im_list = [os.path.join(self.dp, im) for im in self.df['image_name'].values]\n",
    "\n",
    "    def __len__(self):\n",
    "        return ceil(len(self.df) / self.bsz)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffles indexes after each epoch if in training mode\n",
    "        self.indexes = range(len(self.im_list))\n",
    "        if self.mode == 'train':\n",
    "            self.indexes = random.sample(self.indexes, k=len(self.indexes))\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Return labels\n",
    "        if idx == self.__len__() / self.bsz:\n",
    "            return self.labels[idx * self.bsz]\n",
    "        return self.labels[idx * self.bsz: (idx + 1) * self.bsz]\n",
    "\n",
    "    def get_batch_features(self, idx):\n",
    "        # Return images\n",
    "        if idx == self.__len__() / self.bsz:\n",
    "            return [img_to_array(load_img(im)) for im in self.im_list[idx * self.bsz:]]\n",
    "        return np.array([img_to_array(load_img(im)) for im in self.im_list[idx * self.bsz: (1 + idx) * self.bsz]])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.get_batch_features(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a simple Keras model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Dense, Dropout, MaxPool2D, Flatten\n",
    "\n",
    "im_size = 28\n",
    "\n",
    "x = Input(shape=(im_size,im_size, 3))\n",
    "conv_1 = MaxPool2D()(Conv2D(32, (3,3), activation='relu')(x))\n",
    "conv_2 = MaxPool2D()(Conv2D(32, (3,3), activation='relu')(conv_1))\n",
    "conv_3 = MaxPool2D()(Conv2D(32, (3,3), activation='relu')(conv_2))\n",
    "flat = Flatten()(conv_3)\n",
    "dense_1 = Dropout(0.2)(Dense(32, activation='relu')(flat))\n",
    "output = Dense(1, activation='sigmoid')(dense_1)\n",
    "\n",
    "model = Model(inputs=x, outputs=output)\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train the model with the Sequence object and allow for multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 85/125 [===================>..........] - ETA: 0s - loss: 7.9419"
     ]
    }
   ],
   "source": [
    "seq = DataSequence(train, './im',  batch_size=32)\n",
    "model.fit_generator(seq, epochs=5, verbose=1, use_multiprocessing=True, workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (sandbox)",
   "language": "python",
   "name": "sbx3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "480px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
